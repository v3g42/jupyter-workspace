{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import csv as csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import scipy.optimize as opt  \n",
    "from sklearn import metrics, linear_model, tree, ensemble\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ticket_aggr(initTrain, initFinal):\n",
    "    trainFrame = pd.concat([initTrain.drop(['Survived'], axis = 1), initFinal])\n",
    "    a1 = trainFrame.groupby('Ticket')['PassengerId'].count()\n",
    "    a2 = initTrain.groupby('Ticket')['Survived'].sum()\n",
    "    agg = a1.to_frame().join(a2.to_frame()).reset_index()\n",
    "    agg = agg.rename(columns={'PassengerId': 'TicketCount', 'Survived': 'TicketSurvived'})\n",
    "    agg.loc[agg.TicketSurvived.isnull(), 'TicketSurvived'] = 1\n",
    "    agg['TicketSurvived?'] = (agg.TicketSurvived > 1).astype(bool)\n",
    "    agg['TicketCount'] = agg['TicketCount'].astype(int)\n",
    "    agg = agg.drop(['TicketSurvived', 'TicketSurvived?'], axis = 1)\n",
    "    return agg\n",
    "\n",
    "def get_surname_aggr(initTrain, initFinal):\n",
    "    trainFrame = pd.concat([initTrain.drop(['Survived'], axis = 1), initFinal])\n",
    "    a3 = trainFrame.groupby('surname')['PassengerId'].count()\n",
    "    a4 = initTrain.groupby('surname')['Survived'].sum()\n",
    "    agg2 = a3.to_frame().join(a4.to_frame()).reset_index()\n",
    "    agg2 = agg2.rename(columns={'PassengerId': 'SurCount', 'Survived': 'SurSurvived'})\n",
    "    agg2.loc[agg2.SurSurvived.isnull(), 'SurSurvived'] = 1\n",
    "    agg2['SurSurvived?'] = (agg2.SurSurvived > 1).astype(bool)\n",
    "    agg2['SurCount'] = agg2['SurCount'].astype(int)\n",
    "    agg2 = agg2.drop(['SurSurvived', 'SurSurvived?'], axis = 1)    \n",
    "    return agg2\n",
    "\n",
    "def transform_0(dFrame):\n",
    "    t1 = dFrame.Name.str.split(',', expand=True)\n",
    "    t1.columns = ['surname', 'GivenName']\n",
    "    t1['title'] = t1.GivenName.str.extract('(Mrs|Mr|Miss|Master)', expand=False)\n",
    "    dFrame = pd.concat([t1, dFrame], axis=1)\n",
    "    return dFrame\n",
    "\n",
    "def transform_1(dFrame, catTypes, ticket_agg, surname_agg):\n",
    "# Extracting features from Name\n",
    "    dFrame['FamilySize'] = dFrame['SibSp'] + dFrame['Parch']\n",
    "    dFrame = dFrame.drop(['SibSp', 'Parch'], axis=1) \n",
    "    dFrame = dFrame.drop(['PassengerId', 'Name','GivenName', 'Cabin'], axis=1) \n",
    "    dFrame['Child'] = dFrame.Age<16\n",
    "    dFrame['Child'] = dFrame['Child'].astype(bool)\n",
    "    # Factoring in survivors on the same ticket\n",
    "    dFrame = pd.merge(dFrame, ticket_agg, how='left', on='Ticket')\n",
    "\n",
    "\n",
    "    # Factoring in survivors on the same surname\n",
    "    dFrame = pd.merge(dFrame, surname_agg, how='left', on='surname')\n",
    "    \n",
    "    # Fill NA for string fields\n",
    "    for cat in catTypes:\n",
    "        dFrame.loc[dFrame[cat].isnull(), cat] = 'NA'\n",
    "\n",
    "    # Fill fare\n",
    "    dFrame.loc[dFrame.Fare.isnull(),'Fare'] = dFrame.Fare.median()\n",
    "    # Filling Age where it is null\n",
    "    dFrame['AgeIsNull'] = pd.isnull(dFrame.Age).astype(int)\n",
    "\n",
    "    dFrame['EmbarkedIsNull'] = pd.isnull(dFrame.Embarked).astype(int)    \n",
    "    \n",
    "    dFrame['Gender'] = dFrame['Sex'].map({'male': 1, 'female': 0}).astype(int)\n",
    "    median_ages = np.zeros((2,3))\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            median_ages[i,j] = dFrame[(dFrame['Gender'] == i) & \\\n",
    "                              (dFrame['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dFrame.loc[ (dFrame.Age.isnull()) & (dFrame.Gender == i) & (dFrame.Pclass == j+1),\\\n",
    "                'Age'] = median_ages[i,j]\n",
    "    dFrame = dFrame.drop(['Ticket', 'surname', 'Gender'], axis=1)\n",
    "    dFrame['Age*Class'] = dFrame.Age * dFrame.Pclass\n",
    "    return dFrame\n",
    "    \n",
    "def getColumns(t1, t2):\n",
    "    #INIT CATEGORY DICTIONARY\n",
    "    dict = {}\n",
    "    for cat in catTypes:\n",
    "        cct = list(t1[cat].unique()) + list(t2[cat].unique())\n",
    "        dict[cat] = set(cct)\n",
    "    return dict\n",
    "\n",
    "def trainAndTest(clf, test_size=20):\n",
    "    x_train = Xtrain[:test_size]\n",
    "    y_train = ytrain[:test_size]\n",
    "    x_test = Xtrain[test_size:]\n",
    "    y_test = ytrain[test_size:]\n",
    "    clf.fit(x_train, y_train)\n",
    "    print (clf.best_score_, clf.best_params_)\n",
    "    model = clf.best_estimator_\n",
    "    predictions = model.predict(x_train)  \n",
    "    name = type(model).__name__\n",
    "    print(name)\n",
    "    print(\"Train Accuracy {x}, F1 score {f}\".format(x=metrics.accuracy_score(predictions, y_train), f=metrics.f1_score(predictions, y_train)))\n",
    "    predictions_test = model.predict(x_test)  \n",
    "\n",
    "    accuracy = metrics.accuracy_score(predictions_test, y_test)\n",
    "    f1_score = metrics.f1_score(predictions_test, y_test)\n",
    "    print(\"Test Accuracy {x}, F1 score {f}\".format(x=accuracy, f=f1_score))\n",
    "    return {'accuracy': accuracy, f1_score: f1_score, 'model': model, 'name': name, 'predictions': predictions_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data set and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1) train shape (891, 12)\n",
      "-1) final set shape (418, 11)\n",
      "0) train transformed (891, 15)\n",
      "0) final transformed (418, 14)\n",
      "1) train transformed (891, 14)\n",
      "1) final transformed (418, 13)\n",
      "2) training transformed (891, 16)\n",
      "2)final set transformed(418, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:53: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "random_max_depth = 10\n",
    "test_size = 267\n",
    "\n",
    "catTypes = ['Pclass', 'Sex', 'title', 'Embarked']\n",
    "\n",
    "hotTypes = ['Pclass', 'Sex']\n",
    "\n",
    "initTrain = pd.read_csv('./data/train.csv', header=0)\n",
    "print(\"-1) train shape {}\".format(initTrain.shape))\n",
    "initFinal = pd.read_csv('./data/test.csv', header=0)\n",
    "print(\"-1) final set shape {}\".format(initFinal.shape))\n",
    "\n",
    "transTrain = transform_0(initTrain)\n",
    "print(\"0) train transformed {}\".format(transTrain.shape))\n",
    "transFinal = transform_0(initFinal)\n",
    "print(\"0) final transformed {}\".format(transFinal.shape))\n",
    "\n",
    "\n",
    "ticket_agg = get_ticket_aggr(transTrain, transFinal)\n",
    "\n",
    "final_ticket_agg = get_ticket_aggr(transTrain, transFinal)\n",
    "\n",
    "sur_agg = get_surname_aggr(transTrain, transFinal)\n",
    "\n",
    "final_sur_agg = get_surname_aggr(transTrain, transFinal)\n",
    "\n",
    "transTrain = transform_1(transTrain,  catTypes, ticket_agg, sur_agg)\n",
    "print(\"1) train transformed {}\".format(transTrain.shape))\n",
    "transFinal = transform_1(transFinal, catTypes, final_ticket_agg, final_sur_agg)\n",
    "print(\"1) final transformed {}\".format(transFinal.shape))\n",
    "\n",
    "catDict = getColumns(transTrain, transFinal)\n",
    "\n",
    "columns = transTrain.drop(hotTypes+['Survived'], axis=1).columns\n",
    "\n",
    "# Label encoding for string types\n",
    "for cat in catTypes:\n",
    "    lenc = LabelEncoder()\n",
    "    lenc.fit(list(catDict[cat]))\n",
    "    transTrain[cat] = lenc.transform(transTrain[cat])\n",
    "    transFinal[cat] = lenc.transform(transFinal[cat])\n",
    "\n",
    "    \n",
    "Xtrain = transTrain.drop(hotTypes+['Survived'], axis=1).values\n",
    "ytrain = transTrain.Survived.values\n",
    "Xfinal = transFinal.drop(hotTypes, axis=1).values\n",
    "\n",
    "# Hot encoding for few features\n",
    "for cat in hotTypes:\n",
    "    enc = OneHotEncoder(dtype=np.bool)\n",
    "    enc.fit(transTrain[cat].reshape(-1,1))\n",
    "    for r in range(0,enc.n_values_):\n",
    "        columns = np.append(columns, \"{0}_{1}\".format(cat, r))  \n",
    "    train_cat_features = enc.transform(transTrain[cat].reshape(-1,1)).toarray()\n",
    "    test_cat_features = enc.transform(transFinal[cat].reshape(-1,1)).toarray()    \n",
    "    Xtrain = np.concatenate([Xtrain,train_cat_features], axis=1)    \n",
    "    Xfinal = np.concatenate([Xfinal,test_cat_features], axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"2) training transformed {}\".format(Xtrain.shape))\n",
    "print(\"2)final set transformed{}\".format(Xfinal.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786516853933 {'C': 1}\n",
      "LogisticRegression\n",
      "Train Accuracy 0.8164794007490637, F1 score 0.7200000000000001\n",
      "Test Accuracy 0.8012820512820513, F1 score 0.7244444444444443\n",
      "0.797752808989 {'max_depth': 3}\n",
      "DecisionTreeClassifier\n",
      "Train Accuracy 0.8239700374531835, F1 score 0.6928104575163399\n",
      "Test Accuracy 0.8173076923076923, F1 score 0.7298578199052134\n",
      "0.820224719101 {'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 50}\n",
      "RandomForestClassifier\n",
      "Train Accuracy 0.846441947565543, F1 score 0.770949720670391\n",
      "Test Accuracy 0.8349358974358975, F1 score 0.778494623655914\n"
     ]
    }
   ],
   "source": [
    "linear_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "decision_tree_param_grid = {'max_depth':list(range(2,20))}\n",
    "random_param_grid = { \n",
    "    'n_estimators': [5, 10, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth':list(range(2,10))\n",
    "}\n",
    "classifiers = [\n",
    "    GridSearchCV(linear_model.LogisticRegression(solver='liblinear', penalty = 'l2'), linear_param_grid),\n",
    "    GridSearchCV(tree.DecisionTreeClassifier(), decision_tree_param_grid),\n",
    "    GridSearchCV(ensemble.RandomForestClassifier(), random_param_grid)\n",
    "]\n",
    "accuracy = 0\n",
    "model = None\n",
    "results = np.array([])\n",
    "for classifier in classifiers: \n",
    "    result = trainAndTest(classifier, test_size)\n",
    "    results = np.append(results, result)\n",
    "    if(result['accuracy'] > accuracy):\n",
    "        accuracy = result['accuracy']\n",
    "        model = result['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    292\n",
       "1    126\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=5)\n",
    "model.fit(Xtrain, ytrain)\n",
    "yFinal = model.predict(Xfinal) \n",
    "output =  pd.DataFrame({'PassengerId': initFinal.PassengerId, 'Survived':yFinal})\n",
    "output.groupby('Survived').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    263\n",
       "1    155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(C=1,solver='liblinear', penalty = 'l2')\n",
    "model.fit(Xtrain, ytrain)\n",
    "yFinal = model.predict(Xfinal) \n",
    "output =  pd.DataFrame({'PassengerId': initFinal.PassengerId, 'Survived':yFinal})\n",
    "output.groupby('Survived').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    247\n",
       "1    171\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(Xtrain, ytrain)\n",
    "yFinal = model.predict(Xfinal) \n",
    "output =  pd.DataFrame({'PassengerId': initFinal.PassengerId, 'Survived':yFinal})\n",
    "output.groupby('Survived').size()\n",
    "\n",
    "# Decision tree visualisation\n",
    "# tree.export_graphviz(model, './data/tree.dot', feature_names=columns)\n",
    "# dot -Tpng data/tree.dot -o data/tree.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output.to_csv('./data/titanic_{0}_{1}.csv'.format(type(model).__name__, accuracy), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
